@misc{wrap84709,
          volume = {114},
          number = {7},
           month = {April},
          author = {A. Eklund and Thomas E. Nichols and H. Knutsson},
           title = {Reply to Brown and Behrmann, Cox, et al., and Kessler et al. : Data and code sharing is the way forward for fMRI},
       publisher = {National Academy of Sciences},
            year = {2017},
         journal = {Proceedings of the National Academy of Sciences of the United States of America},
           pages = {E3374--E3375},
             url = {http://wrap.warwick.ac.uk/84709/},
        abstract = {We are glad that our paper (1) has generated intense discussions in the fMRI field (2??4), on how to analyze fMRI data, and how to correct for multiple comparisons. The goal of the paper was not to disparage any specific fMRI software, but to point out that parametric statistical methods are based on a number of assumptions that are not always valid for fMRI data, and that nonparametric statistical methods (5) are a good alternative. Through AFNI?s introduction of nonparametric statistics in the function 3dttest++ (3, 6), the three most common fMRI softwares now all support nonparametric group inference [SPM through the toolbox SnPM (www2.warwick.ac.uk/fac/sci/statistics/staff/academic-research/nichols/software/snpm), and FSL through the function randomise].}
}

@article{wrap85042,
          volume = {20},
          number = {3},
           month = {February},
          author = {Thomas E. Nichols and Samir Das and Simon B. Eickhoff and Alan C. Evans and Tristan Glatard and Michael Hanke and Nikolaus Kriegeskorte and Michael P. Milham and Russell A. Poldrack and Jean-Baptiste Poline and Erika Proal and Bertrand Thirion and David C. Van Essen and Tonya White and B.T. Thomas Yeo},
           title = {Best practices in data analysis and sharing in neuroimaging using MRI },
       publisher = {Nature Publishing Group},
            year = {2017},
         journal = {Nature Neuroscience},
           pages = {299--303},
             url = {http://wrap.warwick.ac.uk/85042/},
        abstract = {Given concerns about the reproducibility of scientific findings, neuroimaging must define best 28 practices for data analysis, results reporting, and algorithm and data sharing to promote 29 transparency, reliability and collaboration. We describe insights from developing a set of 30 recommendations on behalf of the Organization for Human Brain Mapping, and identify barriers 31 that impede these practices, including how the discipline must change to fully exploit the 32 potential of the world?s neuroimaging data.}
}

@article{wrap85365,
           month = {January},
           title = {A defense of using resting state fMRI as null data for estimating false positive rates},
          author = {Thomas E. Nichols and Anders Eklund and Hans Knutsson},
       publisher = {Routledge},
            year = {2017},
         journal = {Cognitive Neuroscience},
             url = {http://wrap.warwick.ac.uk/85365/},
        abstract = {A recent Editorial by Slotnick (2017) reconsiders the findings of our paper on the accuracy of false positive rate control with cluster inference in fMRI (Eklund et al, 2016), in particular criticising our use of resting state fMRI data as a source for null data in the evaluation of task fMRI methods. We defend this use of resting fMRI data, as while there is much structure in this data, we argue it is representative of task data noise and as such analysis software should be able to accommodate this noise. We also discuss a potential problem with Slotnick?s own method.}
}

@article{wrap84873,
           month = {January},
           title = {Scanning the horizon : towards transparent and reproducible neuroimaging research},
          author = {Russell A. Poldrack and Chris I. Baker and Joke Durnez and Krzysztof J. Gorgolewski and Paul M. Matthews and Marcus R. Munaf{\`o} and Thomas E. Nichols and Jean-Baptiste Poline and Edward Vul and Tal Yarkoni},
       publisher = {Nature Publishing Group},
            year = {2017},
         journal = {Nature Reviews Neuroscience},
             url = {http://wrap.warwick.ac.uk/84873/},
        abstract = {Functional neuroimaging techniques have transformed our ability to probe the neurobiological basis of behaviour and are increasingly being applied by the wider neuroscience community. However, concerns have recently been raised that the conclusions that are drawn from some human neuroimaging studies are either spurious or not generalizable. Problems such as low statistical power, flexibility in data analysis, software errors and a lack of direct replication apply to many fields, but perhaps particularly to functional MRI. Here, we discuss these problems, outline current and suggested best practices, and describe how we think the field should evolve to produce the most meaningful and reliable answers to neuroscientific questions.}
}

@article{wrap84382,
          volume = {3},
           month = {December},
           title = {Sharing brain mapping statistical results with the neuroimaging data model},
          author = {Camille Maumet and Tibor Auer and Alexander Bowring and Gang Chen and Samir Das and Guillaume Flandin and Satrajit Ghosh and Tristan Glatard and Krzysztof J. Gorgolewski and Karl G. Helmer and Mark Jenkinson and David B. Keator and B. Nolan Nichols and Jean-Baptiste Poline and Richard Reynolds and Vanessa Sochat and Jessica Turner and Thomas E. Nichols},
       publisher = {Nature Publishing Group},
            year = {2016},
         journal = {Scientific Data},
        keywords = {Medical research; Research data},
             url = {http://wrap.warwick.ac.uk/84382/},
        abstract = {Only a tiny fraction of the data and metadata produced by an fMRI study is finally conveyed to the community. This lack of transparency not only hinders the reproducibility of neuroimaging results but also impairs future meta-analyses. In this work we introduce NIDM-Results, a format specification providing a machine-readable description of neuroimaging statistical results along with key image data summarising the experiment. NIDM-Results provides a unified representation of mass univariate analyses including a level of detail consistent with available best practices. This standardized representation allows authors to relay methods and results in a platform-independent regularized format that is not tied to a particular neuroimaging software package. Tools are available to export NIDM-Result graphs and associated files from the widely used SPM and FSL software packages, and the NeuroVault repository can import NIDM-Results archives. The specification is publically available at: http://nidm.nidash.org/specs/nidm-results.html.}
}

@article{wrap83529,
           month = {October},
           title = {Variance decomposition for single-subject task-based fMRI activity estimates across many sessions},
          author = {Javier Gonzalez-Castillo and Gang Chen and Thomas E. Nichols and Peter A. Bandettini},
       publisher = {Elsevier},
            year = {2016},
         journal = {NeuroImage},
             url = {http://wrap.warwick.ac.uk/83529/},
        abstract = {Here we report an exploratory within-subject variance decomposition analysis conducted on a task-based fMRI dataset with an unusually large number of repeated measures (i.e., 500 trials in each of three different subjects) distributed across 100 functional scans and 9 to 10 different sessions. Within-subject variance was segregated into four primary components: variance across-sessions, variance across-runs within a session, variance across-blocks within a run, and residual measurement/modeling error. Our results reveal inhomogeneous and distinct spatial distributions of these variance components across significantly active voxels in grey matter. Measurement error is dominant across the whole brain. Detailed evaluation of the remaining three components shows that across-session variance is the second largest contributor to total variance in occipital cortex, while across-runs variance is the second dominant source for the rest of the brain. Network-specific analysis revealed that across-block variance contributes more to total variance in higher-order cognitive networks than in somatosensory cortex. Moreover, in some higher-order cognitive networks across-block variance can exceed across-session variance. These results help us better understand the temporal (i.e., across blocks, runs and sessions) and spatial distributions (i.e., across different networks) of within-subject natural variability in estimates of task responses in fMRI. They also suggest that different brain regions will show different natural levels of test-retest reliability even in the absence of residual artifacts and sufficiently high contrast-to-noise measurements. Further confirmation with a larger sample of subjects and other tasks is necessary to ensure generality of these results.

}
}

@article{wrap81170,
          volume = {137},
           month = {August},
          author = {Simon B. Eickhoff and Thomas E. Nichols and Angela R. Laird and Felix Hoffstaedter and Katrin Amunts and Peter T. Fox and Danilo Bzdok and Claudia R. Eickhoff},
           title = {Behavior, sensitivity, and power of activation likelihood estimation characterized by massive empirical simulation},
       publisher = {Elsevier},
         journal = {NeuroImage},
           pages = {70--85},
            year = {2016},
             url = {http://wrap.warwick.ac.uk/81170/},
        abstract = {Given the increasing number of neuroimaging publications, the automated knowledge extraction on brain-behavior associations by quantitative meta-analyses has become a highly important and rapidly growing field of research. Among several methods to perform coordinate-based neuroimaging meta-analyses, Activation Likelihood Estimation (ALE) has been widely adopted. In this paper, we addressed two pressing questions related to ALE meta-analysis: i) Which thresholding method is most appropriate to perform statistical inference? ii) Which sample size, i.e., number of experiments, is needed to perform robust meta-analyses? We provided quantitative answers to these questions by simulating more than 120,000 meta-analysis datasets using empirical parameters (i.e., number of subjects, number of reported foci, distribution of activation foci) derived from the BrainMap database. This allowed to characterize the behavior of ALE analyses, to derive first power estimates for neuroimaging meta-analyses, and to thus formulate recommendations for future ALE studies. We could show as a first consequence that cluster-level family-wise error (FWE) correction represents the most appropriate method for statistical inference, while voxel-level FWE correction is valid but more conservative. In contrast, uncorrected inference and false-discovery rate correction should be avoided. As a second consequence, researchers should aim to include at least 20 experiments into an ALE meta-analysis to achieve sufficient power for moderate effects. We would like to note, though, that these calculations and recommendations are specific to ALE and may not be extrapolated to other approaches for (neuroimaging) meta-analysis.

}
}

@article{wrap78399,
          volume = {24},
          number = {4},
           month = {July},
          author = {Audrey Kueh and Jason M. Warnett and Gregory John Gibbons and Julia Brettschneider and Thomas E. Nichols and M. A. Williams and Wilfrid S. Kendall},
           title = {Modelling the penumbra in computed tomography},
       publisher = {I O S Press},
            year = {2016},
         journal = {Journal of X-Ray Science and Technology},
           pages = {583--597},
        keywords = {Computed tomography, focal spot, penumbra, secondary radiation, nonlinear least squares},
             url = {http://wrap.warwick.ac.uk/78399/},
        abstract = {Background: In computed tomography (CT), the spot geometry is one of the main sources of error in CT images. Since X-rays do not arise from a point source, artefacts are produced. In particular there is a penumbra effect, leading to poorly defined edges within a reconstructed volume. Penumbra models can be simulated given a fixed spot geometry and the known experimental setup.
Objective: This paper proposes to use a penumbra model, derived from Beer?s law, both to confirm spot geometry from penumbra data, and to quantify blurring in the image. Methods: Two models for the spot geometry are considered; one consists of a single Gaussian spot, the other is a mixture model consisting of a Gaussian spot together with a larger uniform spot. Results: The model consisting of a single Gaussian spot has a poor fit at the boundary. The mixture model (which adds a larger uniform spot) exhibits a much improved fit. The parameters corresponding to the uniform spot are similar across all powers, and further experiments suggest that the uniform spot produces only soft X-rays of relatively low-energy.
Conclusions: Thus, the precision of radiographs can be estimated from the penumbra effect in the image. The use of a thin copper filter reduces the size of the effective penumbra.}
}

@article{wrap80232,
          volume = {10},
           month = {July},
           title = {Exploring fMRI Results Space : 31 Variants of an fMRI Analysis in AFNI, FSL, and SPM},
          author = {Ruth Pauli and Alexander Bowring and Richard Reynolds and Gang Chen and Thomas E. Nichols and Camille Maumet},
       publisher = {Frontiers Research Foundation},
            year = {2016},
         journal = {Frontiers in neuroinformatics},
        keywords = {Neuroscience ; Standard format neuroimaging data ; Software packages ; Software programs},
             url = {http://wrap.warwick.ac.uk/80232/},
        abstract = {Data sharing is becoming a priority in functional Magnetic Resonance Imaging (fMRI) research, but the lack of a standard format for shared data is an obstacle (Poline et al., 2012; Poldrack and Gorgolewski, 2014). This is especially true for information about data provenance, including auxiliary information such as participant characteristics and task descriptions. The three most commonly used analysis software packages [AFNI1 (Cox, 1996), FSL2 (Jenkinson et al., 2012), and SPM3 (Penny et al., 2011)] broadly conduct the same analysis, but differ in how fundamental concepts are described, and have a myriad of differences in the pre-processing and modeling steps. The practical consequence is that sharing analyzed data is further complicated by the idiosyncrasies of the particular software used.}
}

@article{wrap80355,
          volume = {3},
           month = {June},
           title = {The brain imaging data structure, a format for organizing and describing outputs of neuroimaging experiments},
          author = {Krzysztof J. Gorgolewski and Tibor Auer and Vince D. Calhoun and R. Cameron Craddock and Samir Das and Eugene P. Duff and Guillaume Flandin and Satrajit S. Ghosh and Tristan Glatard and Yaroslav O. Halchenko and Daniel A. Handwerker and Michael Hanke and David Keator and Xiangrui Li and Zachary Michael and Camille Maumet and B. Nolan Nichols and Thomas E. Nichols and John Pellman and Jean-Baptiste Poline and Ariel Rokem and Gunnar Schaefer and Vanessa V. Sochat and William Triplett and Jessica A. Turner and Ga{\"e}l Varoquaux and Russell A. Poldrack},
       publisher = {Nature Publishing Group},
            year = {2016},
         journal = {Scientific Data},
             url = {http://wrap.warwick.ac.uk/80355/},
        abstract = {The development of magnetic resonance imaging (MRI) techniques has defined modern neuroimaging. Since its inception, tens of thousands of studies using techniques such as functional MRI and diffusion weighted imaging have allowed for the non-invasive study of the brain. Despite the fact that MRI is routinely used to obtain data for neuroscience research, there has been no widely adopted standard for organizing and describing the data collected in an imaging experiment. This renders sharing and reusing data (within or between labs) difficult if not impossible and unnecessarily complicates the application of automatic pipelines and quality assurance protocols. To solve this problem, we have developed the Brain Imaging Data Structure (BIDS), a standard for organizing and describing MRI datasets. The BIDS standard uses file formats compatible with existing software, unifies the majority of practices already common in the field, and captures the metadata necessary for most common data processing operations.}
}

@article{wrap76502,
           month = {February},
           title = {Non-parametric combination and related permutation tests for neuroimaging},
          author = {Anderson M. Winkler and Matthew A. Webster and Jonathan C. Brooks and Irene Tracey and Stephen M. Smith and Thomas E. Nichols},
       publisher = {John Wiley and Sons},
            year = {2016},
         journal = {Human Brain Mapping},
             url = {http://wrap.warwick.ac.uk/76502/},
        abstract = {In this work, we show how permutation methods can be applied to combination analyses such as those that include multiple imaging modalities, multiple data acquisitions of the same modality, or simply multiple hypotheses on the same data. Using the well-known definition of union-intersection tests and closed testing procedures, we use synchronized permutations to correct for such multiplicity of tests, allowing flexibility to integrate imaging data with different spatial resolutions, surface and/or volume-based representations of the brain, including non-imaging data. For the problem of joint inference, we propose and evaluate a modification of the recently introduced non-parametric combination (NPC) methodology, such that instead of a two-phase algorithm and large data storage requirements, the inference can be performed in a single phase, with reasonable computational demands. The method compares favorably to classical multivariate tests (such as MANCOVA), even when the latter is assessed using permutations. We also evaluate, in the context of permutation tests, various combining methods that have been proposed in the past decades, and identify those that provide the best control over error rate and power across a range of situations. We show that one of these, the method of Tippett, provides a link between correction for the multiplicity of tests and their combination. Finally, we discuss how the correction can solve certain problems of multiple comparisons in one-way ANOVA designs, and how the combination is distinguished from conjunctions, even though both can be assessed using permutation tests. We also provide a common algorithm that accommodates combination and correction.}
}

@article{wrap67560,
          volume = {9},
           month = {April},
          author = {Krzysztof J. Gorgolewski and Gael Varoquaux and Gabriel Rivera and Yannick Schwarz and Satrajit S. Ghosh and Camille Maumet and Vanessa V. Sochat and Thomas E. Nichols and Russell A. Poldrack and Jean-Baptiste Poline and Tal Yarkoni and Daniel Margulies},
           title = {NeuroVault.org : a web-based repository for collecting and sharing unthresholded statistical maps of the human brain},
       publisher = {Frontiers Research Foundation},
         journal = {Frontiers in neuroinformatics},
           pages = {1--9},
            year = {2015},
             url = {http://wrap.warwick.ac.uk/67560/},
        abstract = {Here we present NeuroVault-a web based repository that allows researchers to store, share, visualize, and decode statistical maps of the human brain. NeuroVault is easy to use and employs modern web technologies to provide informative visualization of data without the need to install additional software. In addition, it leverages the power of the Neurosynth database to provide cognitive decoding of deposited maps. The data are exposed through a public REST API enabling other services and tools to take advantage of it. NeuroVault is a new resource for researchers interested in conducting meta- and coactivation analyses.}
}

@article{wrap65654,
          volume = {Volume 112},
          number = {Number 8},
           month = {February},
          author = {Tian Ge and Thomas E. Nichols and Phil H. Lee and Avram J. Holmes and Joshua L. Roffman and Randy L. Buckner and Mert R. Sabuncu  and Jordan W. Smoller},
           title = {Massively expedited genome-wide heritability analysis (MEGHA)},
       publisher = {National Academy of Sciences },
            year = {2015},
         journal = {Proceedings of the National Academy of Sciences of the United States of America},
           pages = {2479--2484},
             url = {http://wrap.warwick.ac.uk/65654/},
        abstract = {The discovery and prioritization of heritable phenotypes is a computational challenge in a variety of settings, including neuroimaging genetics and analyses of the vast phenotypic repositories in electronic health record systems and population-based biobanks. Classical estimates of heritability require twin or pedigree data, which can be costly and difficult to acquire. Genome-wide Complex Trait Analysis (GCTA) is an alternative tool to compute heritability estimates from unrelated individuals, using genome-wide data that is increasingly ubiquitous, but is computationally demanding and becomes difficult to apply in evaluating very large numbers of phenotypes. Here we present a novel, fast and accurate statistical method for high-dimensional heritability analysis using genome-wide single nucleotide polymorphism (SNP) data from unrelated individuals, termed Massively Expedited Genome-wide Heritability Analysis (MEGHA), and accompanying nonparametric sampling techniques that enable flexible inferences for arbitrary statistics of interest. MEGHA produces estimates and significance measures of heritability with several orders of magnitude less computational time than existing methods, making heritability-based prioritization of millions of phenotypes based on data from unrelated individuals tractable for the first time. As a demonstration of application, we conducted heritability analyses on global and local morphometric measurements derived from brain structural magnetic resonance imaging (MRI) scans, using genome-wide SNP data from 1,320 unrelated young healthy adults of non-Hispanic European ancestry. We also computed surface maps of heritability for cortical thickness measures and empirically localized cortical regions where thickness measures were significantly heritable. Our analyses demonstrate the unique capability of MEGHA for large-scale heritability-based screening and high-dimensional heritability profile construction.}
}

@article{wrap65285,
          volume = {10},
          number = {2},
          author = {Lilia Costa and James Q. Smith and Thomas E. Nichols and James Cussens and Eugene P. Duff and Tamar R. Makin},
           title = {Searching multiregression dynamic models of resting-state fMRI networks using integer programming},
       publisher = {International Society for Bayesian Analysis},
         journal = {Bayesian Analysis},
           pages = {441--478},
            year = {2015},
        keywords = {Multiregression Dynamic Model 

 Bayesian Network 

 Integer Program Algorithm 

 Model selection 

 Functional magnetic resonance imaging (fMRI) },
             url = {http://wrap.warwick.ac.uk/65285/},
        abstract = {A Multiregression Dynamic Model (MDM) is a class of multivariate time series that represents various dynamic causal processes in a graphical way. One of the advantages of this class is that, in contrast to many other Dynamic Bayesian Networks, the hypothesised relationships accommodate conditional conjugate inference. We demonstrate for the first time how straightforward it is to search over all possible connectivity networks with dynamically changing intensity of transmission to find the MAP model within this class. This search method is made feasible by using a novel application of an Integer Programming algorithm. The efficacy of applying this particular class of dynamic models to this domain is shown and more specifically the computational efficiency of a corresponding search of 11-node DAG model space. We proceed to show how diagnostic methods, analogous to those defined for static Bayesian Networks, can be used to suggest embellishment of the model class to extend the process of model selection. All methods are illustrated using simulated and real resting-state functional Magnetic Resonance Imaging (fMRI) data. }
}

@article{wrap63790,
          volume = {Volume 10},
          number = {Number 10},
           month = {August},
          author = {Erin W. Dickie and Amir Tahmasebi and Leon French and Natasa Kovacevic and Tobias Banaschewski and Gareth J. Barker and Arun Bokde and Christian B{\"u}chel and Patricia J. Conrod and Herta Flor and Hugh Garavan and Ju?rgen Gallinat and Penny Gowland and Andreas Heinz and Bernd Ittermann and Claire Lawrence and Karl Mann and Jean-Luc Martinot and Frauke Nees and Thomas E. Nichols and Mark Lathrop and Eva Loth and Zdenka Pausova and Marcela Rietschel and Michal N. Smolka and Andreas Str{\"o}hle and Roberto Toro and Gunter Schumann and Tom{\'a}{\vs} Paus},
           title = {Correction: Global genetic variations predict brain response to faces},
       publisher = {Public Library of Science},
         journal = {PLoS Genetics},
            year = {2014},
             url = {http://wrap.warwick.ac.uk/63790/},
        abstract = {Face expressions are a rich source of social signals. Here we estimated the proportion of phenotypic variance in the brain response to facial expressions explained by common genetic variance captured by {\texttt{\char126}}500,000 single nucleotide polymorphisms. Using genomic-relationship-matrix restricted maximum likelihood (GREML), we related this global genetic variance to that in the brain response to facial expressions, as assessed with functional magnetic resonance imaging (fMRI) in a community-based sample of adolescents (n = 1,620). Brain response to facial expressions was measured in 25 regions constituting a face network, as defined previously. In 9 out of these 25 regions, common genetic variance explained a significant proportion of phenotypic variance (40?50\%) in their response to ambiguous facial expressions; this was not the case for angry facial expressions. Across the network, the strength of the genotype-phenotype relationship varied as a function of the inter-individual variability in the number of functional connections possessed by a given region (R2 = 0.38, p{\ensuremath{<}}0.001). Furthermore, this variability showed an inverted U relationship with both the number of observed connections (R2 = 0.48, p{\ensuremath{<}}0.001) and the magnitude of brain response (R2 = 0.32, p{\ensuremath{<}}0.001). Thus, a significant proportion of the brain response to facial expressions is predicted by common genetic variance in a subset of regions constituting the face network. These regions show the highest inter-individual variability in the number of connections with other network nodes, suggesting that the genetic model captures variations across the adolescent brains in co-opting these regions into the face network.}
}

@article{wrap63626,
          volume = {Volume 9},
          number = {Number 7},
           month = {July},
          author = {Dragana M. Pavlovic and Petra E. V{\'e}rtes and Edward T. Bullmore and William R. Schafer and Thomas E. Nichols},
           title = {Stochastic blockmodeling of the modules and core of the caenorhabditis elegans connectome},
       publisher = {Public Library of Science},
         journal = {PLoS One},
            year = {2014},
             url = {http://wrap.warwick.ac.uk/63626/},
        abstract = {Recently, there has been much interest in the community structure or mesoscale organization of complex networks. This structure is characterised either as a set of sparsely inter-connected modules or as a highly connected core with a sparsely connected periphery. However, it is often difficult to disambiguate these two types of mesoscale structure or, indeed, to summarise the full network in terms of the relationships between its mesoscale constituents. Here, we estimate a community structure with a stochastic blockmodel approach, the Erd{\Ho}s-R{\'e}nyi Mixture Model, and compare it to the much more widely used deterministic methods, such as the Louvain and Spectral algorithms. We used the Caenorhabditis elegans (C. elegans) nervous system (connectome) as a model system in which biological knowledge about each node or neuron can be used to validate the functional relevance of the communities obtained. The deterministic algorithms derived communities with 4?5 modules, defined by sparse inter-connectivity between all modules. In contrast, the stochastic Erd{\Ho}s-R{\'e}nyi Mixture Model estimated a community with 9 blocks or groups which comprised a similar set of modules but also included a clearly defined core, made of 2 small groups. We show that the ?core-in-modules? decomposition of the worm brain network, estimated by the Erd{\Ho}s-R{\'e}nyi Mixture Model, is more compatible with prior biological knowledge about the C. elegans nervous system than the purely modular decomposition defined deterministically. We also show that the blockmodel can be used both to generate stochastic realisations (simulations) of the biological connectome, and to compress network into a small number of super-nodes and their connectivity. We expect that the Erd{\Ho}s-R{\'e}nyi Mixture Model may be useful for investigating the complex community structures in other (nervous) systems.}
}

@article{wrap59944,
          volume = {Volume 94},
           month = {July},
          author = {Bryan Guillaume and Xue Hua and Paul M. Thompson and Lourens Waldorp and Thomas E. Nichols},
           title = {Fast and accurate modelling of longitudinal and repeated measures neuroimaging data},
       publisher = {Elsevier},
         journal = {NeuroImage},
           pages = {287--302},
            year = {2014},
        keywords = {Longitudinal Modelling; Sandwich Estimator; Marginal Modelling; ADNI},
             url = {http://wrap.warwick.ac.uk/59944/},
        abstract = {Despite the growing importance of longitudinal data in neuroimaging, the standard analysis methods make restrictive or unrealistic assumptions (e.g., assumption of Compound Symmetry{--}the state of all equal variances and equal correlations{--}or spatially homogeneous longitudinal correlations). While some new methods have been proposed to more accurately account for such data, these methods are based on iterative algorithms that are slow and failure-prone. In this article, we propose the use of the Sandwich Estimator (SwE) method which first estimates the parameters of interest with a simple Ordinary Least Square model and second estimates variances/covariances with the ?so-called? SwE which accounts for the within-subject correlation existing in longitudinal data. Here, we introduce the SwE method in its classic form, and we review and propose several adjustments to improve its behaviour, specifically in small samples. We use intensive Monte Carlo simulations to compare all considered adjustments and isolate the best combination for neuroimaging data. We also compare the SwE method to other popular methods and demonstrate its strengths and weaknesses. Finally, we analyse a highly unbalanced longitudinal dataset from the Alzheimer's Disease Neuroimaging Initiative and demonstrate the flexibility of the SwE method to fit within- and between-subject effects in a single model. Software implementing this SwE method has been made freely available at http://warwick.ac.uk/tenichols/SwE.}
}

@article{wrap59139,
          volume = {Volume 8},
          number = {Number 2},
           month = {June},
          author = {Thomas E. Nichols},
           title = {The ENIGMA Consortium : large-scale collaborative analyses of neuroimaging and genetic data},
       publisher = {Springer New York LLC},
            year = {2014},
         journal = {Brain Imaging and Behavior},
           pages = {153--182},
             url = {http://wrap.warwick.ac.uk/59139/},
        abstract = {The Enhancing NeuroImaging Genetics through Meta-Analysis (ENIGMA) Consortium is a collaborative network of researchers working together on a range of large-scale studies that integrate data from 70 institutions worldwide. Organized into Working Groups that tackle questions in neuroscience, genetics, and medicine, ENIGMA studies have analyzed neuroimaging data from over 12,826 subjects. In addition, data from 12,171 individuals were provided by the CHARGE consortium for replication of findings, in a total of 24,997 subjects. By meta-analyzing results from many sites, ENIGMA has detected factors that affect the brain that no individual site could detect on its own, and that require larger numbers of subjects than any individual neuroimaging study has currently collected. ENIGMA?s first project was a genome-wide association study identifying common variants in the genome associated with hippocampal volume or intracranial volume. Continuing work is exploring genetic associations with subcortical volumes (ENIGMA2) and white matter microstructure (ENIGMA-DTI). Working groups also focus on understanding how schizophrenia, bipolar illness, major depression and attention deficit/hyperactivity disorder (ADHD) affect the brain. We review the current progress of the ENIGMA Consortium, along with challenges and unexpected discoveries made on the way.}
}

@article{wrap65670,
          volume = {Volume 2},
           month = {May},
          author = {Anderson M. Winkler and Gerard R. Ridgway and Matthew A. Webster and Stephen M. Smith and Thomas E. Nichols},
           title = {Permutation inference for the general linear model},
       publisher = {Elsevier},
         journal = {NeuroImage},
           pages = {381--397},
            year = {2014},
             url = {http://wrap.warwick.ac.uk/65670/},
        abstract = {Permutation methods can provide exact control of false positives and allow the use of non-standard statistics, making only weak assumptions about the data. With the availability of fast and inexpensive computing, their main limitation would be some lack of flexibility to work with arbitrary experimental designs. In this paper we report on results on approximate permutation methods that are more flexible with respect to the experimental design and nuisance variables, and conduct detailed simulations to identify the best method for settings that are typical for imaging research scenarios. We present a generic framework for permutation inference for complex general linear models (glms) when the errors are exchangeable and/or have a symmetric distribution, and show that, even in the presence of nuisance effects, these permutation inferences are powerful while providing excellent control of false positives in a wide range of common and relevant imaging research scenarios. We also demonstrate how the inference on glm parameters, originally intended for independent data, can be used in certain special but useful cases in which independence is violated. Detailed examples of common neuroimaging applications are provided, as well as a complete algorithm ? the ?randomise? algorithm ? for permutation inference with the glm.}
}

@unpublished{wrap65069,
            type = {Working Paper},
           title = {Spatial analysis of dead pixels},
          author = {Julia Brettschneider and John Albert Thornby and Thomas E. Nichols and Wilfrid S. Kendall},
         address = {Coventry, UK},
       publisher = {University of Warwick. Centre for Research in Statistical Methodology},
            year = {2014},
          series = {CRiSM Working Paper Series},
             url = {http://wrap.warwick.ac.uk/65069/},
        abstract = {Considering a rectangular panel of pixels arranged in a grid, we introduce a taxonomy of damages based on spatial arrangements of dysfunctional pixels. We detect these different types of damage in experimental data obtained from a detector from an X-ray machine used for additive layer manufacturing object visualisation. We model the spatial distribution of dysfunctional pixels using point pattern analysis including
 intensity estimation and checking for CSR. As a practical application, we propose a protocol for performance monitoring for detector panels.}
}

@article{wrap56409,
          volume = {Volume 81},
           month = {November},
          author = {Neda Jahanshad and Peter V. Kochunov and Emma Sprooten and Ren{\'e} C. Mandl and Thomas E. Nichols and Laura Almasy and John Blangero and Rachel M. Brouwer and Joanne E. Curran and Greig I. de Zubicaray and Ravi Duggirala and Peter T. Fox and L. Elliot Hong and Bennett A. Landman and Nicholas G. Martin and Katie L. McMahon and Sarah E. Medland and Braxton D. Mitchell and Rene L. Olvera and Charles P. Peterson and John M. Starr and Jessika E. Sussmann and Arthur W. Toga and Joanna M. Wardlaw and Margaret J. Wright and Hilleke E. Hulshoff Pol and Mark E. Bastin and Andrew M. McIntosh and Ian J. Deary and Paul M. Thompson and David C. Glahn},
           title = {Multi-site genetic analysis of diffusion images and voxelwise heritability analysis : a pilot project of the ENIGMA?DTI working group},
       publisher = {Elsevier},
         journal = {NeuroImage},
           pages = {455--469},
            year = {2013},
        keywords = {Diffusion Tensor Imaging (DTI)
Imaging genetics
Heritability
Meta-analysis
Multi-site
Reliability},
             url = {http://wrap.warwick.ac.uk/56409/},
        abstract = {The ENIGMA (Enhancing NeuroImaging Genetics through Meta-Analysis) Consortium was set up to analyze brain measures and genotypes from multiple sites across the world to improve the power to detect genetic variants that influence the brain. Diffusion tensor imaging (DTI) yields quantitative measures sensitive to brain development and degeneration, and some common genetic variants may be associated with white matter integrity or connectivity. DTI measures, such as the fractional anisotropy (FA) of water diffusion, may be useful for identifying genetic variants that influence brain microstructure. However, genome-wide association studies (GWAS) require large populations to obtain sufficient power to detect and replicate significant effects, motivating a multi-site consortium effort. As part of an ENIGMA?DTI working group, we analyzed high-resolution FA images from multiple imaging sites across North America, Australia, and Europe, to address the challenge of harmonizing imaging data collected at multiple sites. Four hundred images of healthy adults aged 18?85 from four sites were used to create a template and corresponding skeletonized FA image as a common reference space. Using twin and pedigree samples of different ethnicities, we used our common template to evaluate the heritability of tract-derived FA measures. We show that our template is reliable for integrating multiple datasets by combining results through meta-analysis and unifying the data through exploratory mega-analyses. Our results may help prioritize regions of the FA map that are consistently influenced by additive genetic factors for future genetic discovery studies. Protocols and templates are publicly available at (http://enigma.loni.ucla.edu/ongoing/dti-working-group/).}
}

@article{wrap56495,
          volume = {Volume 8},
          number = {Number 9},
           month = {September},
          author = {Mario Zeller and Alexander M{\"u}ller and Marcel Gutberlet and Thomas E. Nichols and Dietbert Hahn and Herbert K{\"o}stler and Andreas J. Bartsch},
           title = {Boosting BOLD fMRI by K-Space density weighted echo planar imaging},
       publisher = {Public Library of Science},
            year = {2013},
         journal = {PLoS One},
           pages = {Article number e74501},
             url = {http://wrap.warwick.ac.uk/56495/},
        abstract = {Functional magnetic resonance imaging (fMRI) has become a powerful and influential method to non-invasively study neuronal brain activity. For this purpose, the blood oxygenation level-dependent (BOLD) effect is most widely used. T2* weighted echo planar imaging (EPI) is BOLD sensitive and the prevailing fMRI acquisition technique. Here, we present an alternative to its standard Cartesian recordings, i.e. k-space density weighted EPI, which is expected to increase the signal-to-noise ratio in fMRI data. Based on in vitro and in vivo pilot measurements, we show that fMRI by k-space density weighted EPI is feasible and that this new acquisition technique in fact boosted spatial and temporal SNR as well as the detection of local fMRI activations. Spatial resolution, spatial response function and echo time were identical for density weighted and conventional Cartesian EPI. The signal-to-noise ratio gain of density weighting can improve activation detection and has the potential to further increase the sensitivity of fMRI investigations.}
}

@article{wrap55346,
          volume = {Volume 7},
          number = {Number 2},
           month = {June},
          author = {Alberto Sorrentino and Adam M. Johansen and John A. D. Aston and Thomas E. Nichols and Wilfrid S. Kendall},
           title = {Dynamic filtering of static dipoles in magnetoencephalography
},
       publisher = {Insitute of Mathematical Statistics},
            year = {2013},
         journal = {Annals of Applied Statistics},
           pages = {955--988},
        keywords = {Magnetoencephalography; Multi-object tracking;  Particle filtering; Resample-Move},
             url = {http://wrap.warwick.ac.uk/55346/},
        abstract = {We consider the problem of estimating neural activity from measurements
of the magnetic fields recorded by magnetoencephalography. We exploit
the temporal structure of the problem and model the neural current as a
collection of evolving current dipoles, which appear and disappear, but whose
locations are constant throughout their lifetime. This fully reflects the physiological
interpretation of the model.
In order to conduct inference under this proposed model, it was necessary
to develop an algorithm based around state-of-the-art sequential Monte
Carlo methods employing carefully designed importance distributions. Previous
work employed a bootstrap filter and an artificial dynamic structure
where dipoles performed a random walk in space, yielding nonphysical artefacts
in the reconstructions; such artefacts are not observed when using the
proposed model. The algorithm is validated with simulated data, in which
it provided an average localisation error which is approximately half that of
the bootstrap filter. An application to complex real data derived from a somatosensory
experiment is presented. Assessment of model fit via marginal
likelihood showed a clear preference for the proposed model and the associated
reconstructions show better localisation.}
}

@article{wrap50672,
          volume = {Vol.63},
          number = {No.2},
           month = {November},
          author = {Tian Ge and Jianfeng Feng and Derrek P. Hibar and Paul M. Thompson and Thomas E. Nichols},
           title = {Increasing power for voxel-wise genome-wide association studies : the random field theory, least square kernel machines and fast permutation procedures},
       publisher = {Elsevier},
            year = {2012},
         journal = {NeuroImage},
           pages = {858--873},
             url = {http://wrap.warwick.ac.uk/50672/},
        abstract = {Imaging traits are thought to have more direct links to genetic variation than diagnostic measures based on cognitive or clinical assessments and provide a powerful substrate to examine the influence of genetics on human brains. Although imaging genetics has attracted growing attention and interest, most brain-wide genome-wide association studies focus on voxel-wise single-locus approaches, without taking advantage of the spatial information in images or combining the effect of multiple genetic variants. In this paper we present a fast implementation of voxel- and cluster-wise inferences based on the random field theory to fully use the spatial information in images. The approach is combined with a multi-locus model based on least square kernel machines to associate the joint effect of several single nucleotide polymorphisms (SNP) with imaging traits. A fast permutation procedure is also proposed which significantly reduces the number of permutations needed relative to the standard empirical method and provides accurate small p-value estimates based on parametric tail approximation. We explored the relation between 448,294 single nucleotide polymorphisms and 18,043 genes in 31,662 voxels of the entire brain across 740 elderly subjects from the Alzheimer's Disease Neuroimaging Initiative (ADNI). Structural MRI scans were analyzed using tensor-based morphometry (TBM) to compute 3D maps of regional brain volume differences compared to an average template image based on healthy elderly subjects. We find method to be more sensitive compared with voxel-wise single-locus approaches. A number of genes were identified as having significant associations with volumetric changes. The most associated gene was GRIN2B, which encodes the N-methyl-d-aspartate (NMDA) glutamate receptor NR2B subunit and affects both the parietal and temporal lobes in human brains. Its role in Alzheimer's disease has been widely acknowledged and studied, suggesting the validity of the approach. The various advantages over existing approaches indicate a great potential offered by this novel framework to detect genetic influences on human brains.}
}

@article{wrap39087,
          volume = {Vol.5},
           month = {October},
          author = {Peter Kochunov and David C. Glahn and Thomas E. Nichols and Anderson M. Winkler and Elliot L. Hong and Henry H. Holcomb and Jason L. Stein and Paul M. Thompson and Joanne E. Curran and Melanie A. Carless and Rene L. Olvera and Matthew P. Johnson and Shelley A. Cole and Valeria Kochunov and Jack Kent and John Blangero},
           title = {Genetic analysis of cortical thickness and fractional anisotropy of water diffusion in the brain},
       publisher = {Frontiers Media S.A},
         journal = {Frontiers in Neuroscience},
           pages = {120},
            year = {2011},
             url = {http://wrap.warwick.ac.uk/39087/},
        abstract = {Objectives: The thickness of the brain?s cortical gray matter (GM) and the fractional
anisotropy (FA) of the cerebral white matter (WM) each follow an inverted U-shape trajectory
with age. The two measures are positively correlated and may be modulated by
common biological mechanisms. We employed four types of genetic analyses to localize
individual genes acting pleiotropically upon these phenotypes. Methods: Whole-brain
and regional GM thickness and FA values were measured from high-resolution anatomical
and diffusion tensor MR images collected from 712, Mexican American participants (438
females, age=47.9{$\pm$}13.2 years) recruited from 73 (9.7{$\pm$}9.3 individuals/family) large families.
The significance of the correlation between two traits was estimated using a bivariate
genetic correlation analysis. Localization of chromosomal regions that jointly influenced
both traits was performed using whole-genome quantitative trait loci (QTL) analysis. Gene
localization was performed using SNP genotyping on Illumina 1M chip and correlation with
leukocyte-based gene-expression analyses. The gene-expressions were measured using
the Illumina BeadChip. These data were available for 371 subjects. Results: Significant
genetic correlationwas observed amongGMthickness and FA values. Significant logarithm
of odds (LOD?3.0) QTLs were localized within chromosome 15q22?23. More detailed
localization reported no significant association (p {\ensuremath{<}}5?10?5) for 1565 SNPs located within
the QTLs. Post hoc analysis indicated that 40\% of the potentially significant (p {$\leq$}10?3)
SNPs were localized to the related orphan receptor alpha (RORA) and NARG2 genes. A
potentially significant association was observed for the rs2456930 polymorphism reported
as a significant GWAS finding in Alzheimer?s disease neuroimaging initiative subjects. The
expression levels for RORA and ADAM10 genes were significantly (p {\ensuremath{<}}0.05) correlated
with both FA and GM thickness. NARG2 expressions were significantly correlated with
GM thickness (p {\ensuremath{<}}0.05) but failed to show a significant correlation (p =0.09) with FA. Discussion:
This study identified a novel, significant QTL at 15q22?23. SNP correlation with
gene-expression analyses indicated that RORA, NARG2, and ADAM10 jointly influenceGM
thickness and WM?FA values.}
}

@article{wrap36875,
          volume = {Vol.6},
          number = {No.7},
           month = {July},
          author = {Cedric E. Ginestet and Thomas E. Nichols and Edward T. Bullmore and Andrew Simmons},
           title = {Brain network analysis : separating cost from topology using cost-integration},
       publisher = {Public Library of Science},
            year = {2011},
         journal = {PLoS ONE},
           pages = {Article: e21570},
        keywords = {SMALL-WORLD NETWORKS; FUNCTIONAL CONNECTIVITY; CORTICAL NETWORKS; EFFICIENCY; BEHAVIOR; SCHIZOPHRENIA; ORGANIZATION; FREQUENCY; DYNAMICS; MODELS},
             url = {http://wrap.warwick.ac.uk/36875/},
        abstract = {A statistically principled way of conducting brain network analysis is still lacking. Comparison of different populations of
brain networks is hard because topology is inherently dependent on wiring cost, where cost is defined as the number of
edges in an unweighted graph. In this paper, we evaluate the benefits and limitations associated with using cost-integrated
topological metrics. Our focus is on comparing populations of weighted undirected graphs that differ in mean association
weight, using global efficiency. Our key result shows that integrating over cost is equivalent to controlling for any
monotonic transformation of the weight set of a weighted graph. That is, when integrating over cost, we eliminate the
differences in topology that may be due to a monotonic transformation of the weight set. Our result holds for any
unweighted topological measure, and for any choice of distribution over cost levels. Cost-integration is therefore helpful in
disentangling differences in cost from differences in topology. By contrast, we show that the use of the weighted version of
a topological metric is generally not a valid approach to this problem. Indeed, we prove that, under weak conditions, the
use of the weighted version of global efficiency is equivalent to simply comparing weighted costs. Thus, we recommend the
reporting of (i) differences in weighted costs and (ii) differences in cost-integrated topological measures with respect to
different distributions over the cost domain. We demonstrate the application of these techniques in a re-analysis of an fMRI
working memory task. We also provide a Monte Carlo method for approximating cost-integrated topological measures.
Finally, we discuss the limitations of integrating topology over cost, which may pose problems when some weights are zero,
when multiplicities exist in the ranks of the weights, and when one expects subtle cost-dependent topological differences,
which could be masked by cost-integration.}
}

@article{wrap708,
          volume = {Vol.11},
          number = {No.4},
           month = {April},
          author = {Alistair B.A.                    Boxall and Anthony Hardy and Sabine Beulke and Tatiana  Boucard and Laura Burgin and Peter D.  Falloon and Philip M. Haygarth and Thomas Hutchinson and R. Sari  Kovats and Giovanni  Leonardi and Leonard S.  Levy and Gordon Nichols and Simon Parsons and Laura Potts and David Stone and Edward Topp and David B. Turley and Kerry Walsh and E. M. H. Wellington and Richard J. Williams},
           title = {Impacts of Climate Change on indirect human exposure to pathogens and chemicals from agriculture },
       publisher = {US Department of Health and Human Services},
            year = {2009},
         journal = {Environmental Health Perspectives},
           pages = {508--514},
             url = {http://wrap.warwick.ac.uk/708/},
        abstract = {Objective: Climate change is likely to affect the nature of pathogens and chemicals in the environment and their fate and transport. Future risks of pathogens and chemicals could therefore be very different from those of today. In this review, we assess the implications of climate change for changes in human exposures to pathogens and chemicals in agricultural systems in the United Kingdom and discuss the subsequent effects on health impacts. 

Data sources: In this review, we used expert input and considered literature on climate change ; health effects resulting from exposure to pathogens and chemicals arising from agriculture ; inputs of chemicals and pathogens to agricultural systems ; and human exposure pathways for pathogens and chemicals in agricultural systems. 

Data synthesis: We established the current evidence base for health effects of chemicals and pathogens in the agricultural environment ; determined the potential implications of climate change on chemical and pathogen inputs in agricultural systems ; and explored the effects of climate change on environmental transport and fate of different contaminant types. We combined these data to assess the implications of climate change in terms of indirect human exposure to pathogens and chemicals in agricultural systems. We then developed recommendations on future research and policy changes to manage any adverse increases in risks. 

Conclusions: Overall, climate change is likely to increase human exposures to agricultural contaminants. The magnitude of the increases will be highly dependent on the contaminant type. Risks from many pathogens and particulate and particle-associated contaminants could increase significantly. These increases in exposure can, however, be managed for the most part through targeted research and policy changes.}
}

@article{wrap38355,
          volume = {Vol.18},
           month = {October},
          author = {Sumitra Purkayastha and Tor D. Wager and Thomas E. Nichols},
           title = {Inferring individual differences in fMRI : finding brain regions with significant within subject correlation},
       publisher = {Academia Sinica * Institute of Statistical Science},
         journal = {Statistica Sinica},
           pages = {1483--1500},
            year = {2008},
        keywords = {Attention switching; functional magnetic resonance imaging; likelihood ratio test; mixed model},
             url = {http://wrap.warwick.ac.uk/38355/},
        abstract = {Functional magnetic resonance imaging studies answer questions about activation effects in populations of subjects. To begin with, this involves appropriate modelling of the fMRI data at the within-subject level. This is followed by extending the model to multiple subjects. There have been several attempts toward this extension, all of which have focused on inference on a single effect of interest (e.g., fMRI response for one type of working memory). However, the existing literature does not seem to say much about the relevant inferential procedures when multiple effects are of interest (e.g., response for four different types of working memory). In particular, the within subject dependence of one activation effect on another is an important issue with a multivariate repeated measures model. While most standard statistical methods regard such correlation as a nuisance, to be adjusted for and then ignored, we develop two simple and intuitive tests to make inference on the existence of such correlation. We demonstrate use of these tests by application to an fMRI study of attention switching. These tests are different not only from conventional tests for sphericity but also, more importantly, from the likelihood ratio test (LRT) of the relevant hypothesis. We also discuss what prompts us to look for tests different from the LRT.}
}

@article{wrap38356,
          volume = {Vol.25},
          number = {No.2},
          author = {Jeanette A. Mumford and Thomas E. Nichols},
           title = {Modeling and inference of multisubject fMRI data},
       publisher = {IEEE},
         journal = {IEEE Engineering in Medicine and Biology Magazine},
           pages = {42--51},
            year = {2006},
             url = {http://wrap.warwick.ac.uk/38356/},
        abstract = {Functional magnetic resonance imaging (fMRI) is a
rapidly growing technique for studying the brain in
action. Since its creation [1], [2], cognitive scientists
have been using fMRI to understand how we remember,
manipulate, and act on information in our environment.
Working with magnetic resonance physicists, statisticians, and
engineers, these scientists are pushing the frontiers of knowledge
of how the human brain works.
The design and analysis of single-subject fMRI studies
has been well described. For example, [3], chapters 10
and 11 of [4], and chapters 11 and 14 of [5] all give accessible
overviews of fMRI methods for one subject. In contrast,
while the appropriate manner to analyze a group of
subjects has been the topic of several recent papers, we do
not feel it has been covered well in introductory texts and
review papers. Therefore, in this article, we bring together
old and new work on so-called group modeling of fMRI
data using a consistent notation to make the methods more
accessible and comparable.}
}
